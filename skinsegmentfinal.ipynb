{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshat/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import imutils\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.backend import resize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_colors(hist, centroids):\n",
    "    # initialize the bar chart representing the relative frequency\n",
    "    # of each of the colors\n",
    "    bar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    # loop over the percentage of each cluster and the color of\n",
    "    # each cluster\n",
    "    for (percent, color) in zip(hist, centroids):\n",
    "        # plot the relative percentage of each cluster\n",
    "        endX = startX + (percent * 300)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "            color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "\n",
    "    # return the bar chart\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "    # normalize the histogram, such that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    # return the histogram\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This has the best result\n",
    "def extractSkin3(image, color, default = True):\n",
    "#     print(color)\n",
    "#     color.reverse() #bgr\n",
    "#     color[0] =   16 +  65.738*color[2]/256 + 129.057*color[1]/256 +  25.064*color[0]/256\n",
    "#     Cb = 128 -  37.945*color[2]/256 -  74.494*color[1]/256 + 112.439*color[0]/256\n",
    "#     Cr = 128 + 112.439*color[2]/256 -  94.154*color[1]/256 -  18.285*color[0]/256\n",
    "#     thresh = 20\n",
    "#     print(color)\n",
    "\n",
    "\n",
    "    if default == False:\n",
    "        color.reverse() #bgr\n",
    "    #     cv2.imshow('domcol', np.uint8( [[color]] ))\n",
    "        color = cv2.cvtColor( np.uint8( [[color]] ), cv2.COLOR_BGR2YCrCb)[0][0]\n",
    "        thresh = 50 \n",
    "\n",
    "    \n",
    "    # Taking a copy of the image\n",
    "    img = image.copy()\n",
    "    # Converting from BGR Colours Space to HSV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # Defining HSV Threadholds\n",
    "    if default == True:\n",
    "        skin_ycrcb_mint = np.array((0, 133, 77))\n",
    "        skin_ycrcb_maxt = np.array((255, 173, 127))\n",
    "    else:\n",
    "        skin_ycrcb_mint = np.array([color[0] - thresh, color[1] - thresh, color[2] - thresh])\n",
    "        skin_ycrcb_maxt = np.array([color[0] + thresh, color[1] + thresh, color[2] + thresh])\n",
    "\n",
    "    # Single Channel mask,denoting presence of colours in the about threshold\n",
    "    skinMask =  cv2.inRange(img, skin_ycrcb_mint, skin_ycrcb_maxt)\n",
    "    \n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    \n",
    "    # Cleaning up mask using Gaussian Filter\n",
    "    skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
    "\n",
    "    # Extracting skin from the threshold mask\n",
    "    skin = cv2.bitwise_and(img, img, mask=skinMask)\n",
    "\n",
    "    # Return the Skin image\n",
    "    return cv2.cvtColor(skin, cv2.COLOR_YCR_CB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color(image, k=4, image_processing_size = None):\n",
    "    \"\"\"\n",
    "    takes an image as input\n",
    "    returns the dominant color of the image as a list\n",
    "    \n",
    "    dominant color is found by running k means on the \n",
    "    pixels & returning the centroid of the largest cluster\n",
    "\n",
    "    processing time is sped up by working with a smaller image; \n",
    "    this resizing can be done with the image_processing_size param \n",
    "    which takes a tuple of image dims as input\n",
    "\n",
    "    >>> get_dominant_color(my_image, k=4, image_processing_size = (25, 25))\n",
    "    [56.2423442, 34.0834233, 70.1234123]\n",
    "    \"\"\"\n",
    "    #resize image if new dims provided\n",
    "    if image_processing_size is not None:\n",
    "        image = cv2.resize(image, image_processing_size, \n",
    "                            interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #reshape the image to be a list of pixels\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "    #cluster and assign labels to the pixels \n",
    "    clt = KMeans(n_clusters = k)\n",
    "    labels = clt.fit_predict(image)\n",
    "\n",
    "    #count labels to find most popular\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    #subset out most popular centroid\n",
    "    dominant_color = clt.cluster_centers_[label_counts.most_common(1)[0][0]]\n",
    "    \n",
    "    hist = centroid_histogram(clt)\n",
    "    bar = plot_colors(hist, clt.cluster_centers_)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(bar)\n",
    "    plt.show()\n",
    "\n",
    "    return list(dominant_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectface(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    color = 0\n",
    "    fobj = image \n",
    "    flag = 0\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        fobj = image[y:y+h, x:x+w]\n",
    "        flag = 1\n",
    "    \n",
    "    if flag == 1:\n",
    "        color = get_dominant_color(fobj)\n",
    "    \n",
    "    cv2.imshow('face', fobj)\n",
    "    \n",
    "    \n",
    "    return color, flag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAABTUlEQVR4nO3asU0EQRBFwV2ExHG5EgQeeKRAcpxEBodBEwEICfTG2Cp3nG89tTH7zGwANG5WDwA4EtEFCIkuQEh0AUKiCxASXYDQ7U+Pr8+P/pP9s5nZ3t8uq2f82t3ptN2fz6tn8Acf1+s287l6xqE8PL3s3725dAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQjtM7N6A8BhuHQBQqILEBJdgJDoAoREFyAkugChLxF8Fod+DwyoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAABUUlEQVR4nO3aIW5CQRRA0f9Jl4YguDp0sd0D2yQIFKJNmpKuYLoCEIj7xT/HvsnkqZsRM48xJgAam6UXAFgT0QUIiS5ASHQBQqILEBJdgNDbs+Hn+85/ssjt5z5dbl9LrwGr8Pv3MX3fT0/PHI/n6XC4vnT/drufH828dAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQjNY4yldwBYDS9dgJDoAoREFyAkugAh0QUIiS5A6B8ttBaHpdDIzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0) \n",
    "start_point = (50,100)\n",
    "end_point = (300, 350)  \n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    frame2 = frame.copy()\n",
    "    \n",
    "    frame = cv2.rectangle(frame, start_point, end_point, color=(0,0,255), thickness=2)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    cv2.imshow('get skin color', frame)\n",
    "    \n",
    "    pressedKey = cv2.waitKey(1) & 0xFF\n",
    "    if(pressedKey == ord('c')):\n",
    "        frame2 = frame2[100:350,50:300]\n",
    "        color1 = get_dominant_color(frame2)\n",
    "        cv2.imshow('hand image', frame2)\n",
    "    \n",
    "    if(pressedKey == ord('q')):\n",
    "        break\n",
    "        \n",
    "        \n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    color2, flag = detectface(frame)\n",
    "    \n",
    "    if flag == 1:\n",
    "        break\n",
    "        \n",
    "    print(color2)\n",
    "    \n",
    "cv2.destroyAllWindows() \n",
    "        \n",
    "while(True): \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read() \n",
    "    frame3 = frame.copy()\n",
    "    frame4 = frame.copy()\n",
    "    frame5 = frame.copy()\n",
    "    \n",
    "    frame3 = cv2.flip(frame3, 1)\n",
    "    frame4 = cv2.flip(frame4, 1)\n",
    "    frame5 = cv2.flip(frame5, 1)\n",
    "    \n",
    "    frame3 = extractSkin3(frame3, color1, default = False)\n",
    "    frame4 = extractSkin3(frame4, color2, default = False)\n",
    "    frame5 = extractSkin3(frame5, color1, default = True)\n",
    "    \n",
    "    cv2.imshow('from hand color', frame3)\n",
    "    cv2.imshow('from face color', frame4)\n",
    "    cv2.imshow('from default skin color', frame5)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
