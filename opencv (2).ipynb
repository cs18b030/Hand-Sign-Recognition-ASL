{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import math\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.backend import resize_images\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Branch models added\n"
     ]
    }
   ],
   "source": [
    "model_all = load_model('/home/venkat/Downloads/trial_all_class_weight.h5')\n",
    "model_correct = load_model('/home/venkat/Downloads/trial_correct.h5')\n",
    "model_curve = load_model('/home/venkat/Downloads/trial_curve.h5')\n",
    "model_fingers_up = load_model('/home/venkat/Downloads/trial_fingers_up.h5')\n",
    "model_fist = load_model('/home/venkat/Downloads/trial_fist.h5')\n",
    "model_lkxy = load_model('/home/venkat/Downloads/trial_lkxy.h5')\n",
    "model_point = load_model('/home/venkat/Downloads/trial_point.h5')\n",
    "print(\"Model loaded!\")\n",
    "branch = {}\n",
    "branch[0] = model_fist\n",
    "branch[1] = model_fingers_up\n",
    "branch[2] = model_curve\n",
    "branch[3] = model_fingers_up\n",
    "branch[4] = model_fist\n",
    "branch[5] = model_correct\n",
    "branch[6] = model_point\n",
    "branch[7] = model_point\n",
    "branch[8] = model_fingers_up\n",
    "branch[10] = model_lkxy\n",
    "branch[11] = model_lkxy\n",
    "branch[12] = model_fist\n",
    "branch[13] = model_fist\n",
    "branch[14] = model_curve\n",
    "branch[15] = model_correct\n",
    "branch[16] = model_correct\n",
    "branch[17] = model_fingers_up\n",
    "branch[18] = model_fist\n",
    "branch[19] = model_point\n",
    "branch[20] = model_fingers_up\n",
    "branch[21] = model_correct\n",
    "branch[22] = model_correct\n",
    "branch[23] = model_lkxy\n",
    "branch[24] = model_lkxy\n",
    "print(\"Branch models added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Pictures Taken!\n"
     ]
    }
   ],
   "source": [
    "videoCaptureObject = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "ret = True\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (480,640))\n",
    "start_point = (50,100)\n",
    "end_point = (300, 350) \n",
    "c = 0\n",
    "# l=[]\n",
    "po = np.zeros((25,1))\n",
    "\n",
    "while(ret):\n",
    "    ret,frame = videoCaptureObject.read()\n",
    "    if ret == True:\n",
    "        clone = frame.copy() \n",
    "        frame = cv2.rectangle(frame, start_point, end_point, color=(0,0,255), thickness=2)\n",
    "        \n",
    "        if c%5==0:\n",
    "            crop_img = clone[100:350,50:300]\n",
    "            resized_img = cv2.resize(crop_img,(100,100))\n",
    "\n",
    "            img = cv2.cvtColor(resized_img ,cv2.COLOR_BGR2YUV)\n",
    "            img[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "            img_hist = cv2.cvtColor(img, cv2.COLOR_YUV2RGB)\n",
    "            denoised = cv2.bilateralFilter(img_hist, 7, 100, 100) \n",
    "            v = np.median(denoised)\n",
    "            lower = int(max(0, (1.0 - 0.33) * v))\n",
    "            upper = int(min(255, (1.0 + 0.33) * v))\n",
    "            img_blur_canny = cv2.Canny(denoised,lower,upper)\n",
    "            \n",
    "            x_test = np.asarray(denoised)\n",
    "            x_test = x_test.astype('float32')\n",
    "            y_pred = model_all.predict(x_test.reshape((1,100,100,3)), batch_size=None, steps=1)\n",
    "            display_text = \"\"\n",
    "            max_pred = np.max(y_pred)\n",
    "            if(max_pred>0.5):\n",
    "                index = np.argmax(y_pred)\n",
    "                model_temp = branch[index]\n",
    "                y_branch = model_temp.predict(x_test.reshape((1,100,100,3)), batch_size=None, steps=1)\n",
    "                display_text = \"Alphabet - \" + chr(ord('A') + np.argmax(y_branch))\n",
    "            else:\n",
    "                display_text = \"Need better picture\"\n",
    "        c += 1  \n",
    "        frame = cv2.flip(frame,1)\n",
    "        cv2.putText(frame, display_text, (340, 95), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255), 3)\n",
    "        cv2.imshow('ASL Alphabet Classification', frame)\n",
    "        # doesn't work with colab (cv2.imshow)\n",
    "        \n",
    "        \n",
    "        out.write(frame)\n",
    "        pressedKey = cv2.waitKey(1) & 0xFF\n",
    "        if(pressedKey == ord('c')):\n",
    "            \n",
    "            cv2.imwrite(\"A/A\"+ str(i)+\".jpg\",resized_img)\n",
    "            plt.imshow(resized_img, vmin=0, vmax=255)\n",
    "            plt.show()\n",
    "            i += 1\n",
    "        elif(pressedKey == ord('q')):\n",
    "            videoCaptureObject.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Happy Pictures Taken!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
